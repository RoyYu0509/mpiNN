{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78432903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>process_num</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>sgd_iter_time_mean</th>\n",
       "      <th>testing_time_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.559103</td>\n",
       "      <td>4.340288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.631908</td>\n",
       "      <td>11.457897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1.031369</td>\n",
       "      <td>5.895992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.344205</td>\n",
       "      <td>3.543477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.950509</td>\n",
       "      <td>9.366346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.571791</td>\n",
       "      <td>3.996511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.264911</td>\n",
       "      <td>2.481092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.672279</td>\n",
       "      <td>8.212471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.424638</td>\n",
       "      <td>2.861514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   process_num activation_function  sgd_iter_time_mean  testing_time_mean\n",
       "0            1                relu            0.559103           4.340288\n",
       "1            1             sigmoid            1.631908          11.457897\n",
       "2            1                tanh            1.031369           5.895992\n",
       "3            2                relu            0.344205           3.543477\n",
       "4            2             sigmoid            0.950509           9.366346\n",
       "5            2                tanh            0.571791           3.996511\n",
       "6            3                relu            0.264911           2.481092\n",
       "7            3             sigmoid            0.672279           8.212471\n",
       "8            3                tanh            0.424638           2.861514"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improved visualization with deduplicated group headers for \"process_num\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "csv_path = \"table/summary_metrics.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "def pick_col(cands, cols, required=True):\n",
    "    for c in cands:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Missing one of columns {cands}. Found: {list(cols)}\")\n",
    "    return None\n",
    "\n",
    "col_process   = pick_col([\"process_num\",\"process_number\",\"p_num\",\"process\"], df.columns)\n",
    "col_act       = pick_col([\"act_func\",\"activation\",\"activation_function\",\"act_name\"], df.columns)\n",
    "col_batch     = pick_col([\"batch_size\",\"batch_portion\",\"batch\",\"b\"], df.columns)\n",
    "col_sgd_time  = pick_col([\"sgd_iter_time\",\"sgd_time\",\"iter_time\",\"max_time\",\"training_time\"], df.columns)\n",
    "col_test_time = pick_col([\"testing_time\",\"test_time\"], df.columns, required=False)\n",
    "\n",
    "for c in [col_process, col_batch, col_sgd_time, col_test_time]:\n",
    "    if c is not None and c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# ---- Table 1: mean times by process × activation ----\n",
    "value_cols = [col_sgd_time] + ([col_test_time] if col_test_time else [])\n",
    "df_group_proc_act = (\n",
    "    df.groupby([col_process, col_act], dropna=False)[value_cols]\n",
    "      .mean(numeric_only=True)\n",
    "      .reset_index()\n",
    "      .rename(columns={\n",
    "          col_process: \"process_num\",\n",
    "          col_act: \"activation_function\",\n",
    "          col_sgd_time: \"sgd_iter_time_mean\",\n",
    "          **({col_test_time: \"testing_time_mean\"} if col_test_time else {})\n",
    "      })\n",
    ")\n",
    "\n",
    "# Sort for clean grouped view\n",
    "sort_cols = [\"process_num\", \"activation_function\"]\n",
    "df_group_proc_act = df_group_proc_act.sort_values(sort_cols)\n",
    "\n",
    "# Visualization copy: avoid repeating the same process_num\n",
    "vis1 = df_group_proc_act.copy()\n",
    "vis1[\"process_num\"] = vis1[\"process_num\"].where(\n",
    "    vis1[\"process_num\"].ne(vis1[\"process_num\"].shift()), \"\"\n",
    ")\n",
    "\n",
    "# Optional formatting of time columns\n",
    "for c in [\"sgd_iter_time_mean\", \"testing_time_mean\"]:\n",
    "    if c in vis1.columns:\n",
    "        vis1[c] = vis1[c].map(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"\")\n",
    "\n",
    "# ---- Table 2: mean of numeric columns by batch size (clean) ----\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols_wo_key = [c for c in numeric_cols if c != col_batch]\n",
    "\n",
    "df_group_batch = (\n",
    "    df.groupby(col_batch, as_index=False)[numeric_cols_wo_key]\n",
    "      .mean(numeric_only=True)\n",
    "      .rename(columns={col_batch: \"batch_size\"})\n",
    "      .sort_values(\"batch_size\")\n",
    ")\n",
    "\n",
    "# Optional: round numeric means for readability\n",
    "round_cols = df_group_batch.select_dtypes(include=[np.number]).columns\n",
    "df_group_batch[round_cols] = df_group_batch[round_cols].round(3)\n",
    "\n",
    "# # Save & display both nice tables\n",
    "# out1 = \"/mnt/data/df_group_proc_act_pretty.csv\"\n",
    "# out2 = \"/mnt/data/df_group_batch_pretty.csv\"\n",
    "# df_group_proc_act.to_csv(out1, index=False)  # save the true aggregated data\n",
    "# df_group_batch.to_csv(out2, index=False)\n",
    "\n",
    "\n",
    "df_group_proc_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dc31eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def plot_training_history(\n",
    "    df: pd.DataFrame,\n",
    "    x_col: str,\n",
    "    y_cols: list,\n",
    "    title: str = \"Training History\",\n",
    "    xlabel: str = \"Epoch / Iteration\",\n",
    "    ylabel: str = \"Metric Value\",\n",
    "    legend_fontsize: int = 10,\n",
    "    axis_fontsize: int = 12,\n",
    "    figsize=(7, 6),\n",
    "    alpha: float = 0.8,\n",
    "    grid: bool = True,\n",
    "    save_path: str = \"training_history.pdf\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Robust plotting function for training history, with PDF output.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Data containing metrics.\n",
    "        x_col (str): Column name for x-axis (e.g., 'epoch').\n",
    "        y_cols (list): List of column names to plot (e.g., ['train_RMSE', 'val_RMSE']).\n",
    "        title, xlabel, ylabel: Text for title and axes.\n",
    "        legend_fontsize, axis_fontsize: Font sizes.\n",
    "        figsize (tuple): Figure size (width, height).\n",
    "        alpha (float): Line transparency.\n",
    "        grid (bool): Whether to show grid lines.\n",
    "        save_path (str): Path (with or without .pdf) to save the figure.\n",
    "    \"\"\"\n",
    "    # Normalize extension\n",
    "    if not save_path.lower().endswith(\".pdf\"):\n",
    "        save_path = os.path.splitext(save_path)[0] + \".pdf\"\n",
    "\n",
    "    actual_cols = [c.lower() for c in df.columns]\n",
    "    plotted = False\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for col in y_cols:\n",
    "        # Case-insensitive matching\n",
    "        match = [c for c in df.columns if c.lower() == col.lower()]\n",
    "        if not match:\n",
    "            print(f\"[Warning] Column '{col}' not found in DataFrame. Skipping.\")\n",
    "            continue\n",
    "        plt.plot(df[x_col], np.sqrt(df[match[0]]), label=match[0], alpha=alpha, linewidth=2)\n",
    "        plotted = True\n",
    "\n",
    "    if not plotted:\n",
    "        print(\"[Error] No valid columns plotted. Please check column names.\")\n",
    "        return\n",
    "\n",
    "    plt.title(title, fontsize=axis_fontsize + 2)\n",
    "    plt.xlabel(xlabel, fontsize=axis_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=axis_fontsize)\n",
    "    plt.legend(fontsize=legend_fontsize)\n",
    "    if grid:\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(save_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "    print(f\"✅ Plot saved as PDF: {os.path.abspath(save_path)}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0bf2dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Plot saved as PDF: /Users/yifanyu/Desktop/mpiNN/relu_training_history.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_path = \"train_his_csv/loss_record_relu.csv\"\n",
    "df_relu = pd.read_csv(csv_path)\n",
    "\n",
    "plot_training_history(\n",
    "    df_relu,\n",
    "    x_col=\"epoch\",\n",
    "    y_cols=[\"train_loss\", \"val_loss\"],\n",
    "    title=\"ReLu Activation Training History\",\n",
    "    xlabel=\"Epoch\",\n",
    "    ylabel=\"RMSE\",\n",
    "    legend_fontsize=17,\n",
    "    axis_fontsize=16,\n",
    "    alpha=0.9,\n",
    "    save_path = \"relu_training_history.pdf\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38211730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Plot saved as PDF: /Users/yifanyu/Desktop/mpiNN/sigmoid_training_history.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_path = \"train_his_csv/loss_record_sigmoid.csv\"\n",
    "df_relu = pd.read_csv(csv_path)\n",
    "\n",
    "plot_training_history(\n",
    "    df_relu,\n",
    "    x_col=\"epoch\",\n",
    "    y_cols=[\"train_loss\", \"val_loss\"],\n",
    "    title=\"Sigmoid Activation Training History\",\n",
    "    xlabel=\"Epoch\",\n",
    "    ylabel=\"RMSE\",\n",
    "    legend_fontsize=17,\n",
    "    axis_fontsize=16,\n",
    "    alpha=0.9,\n",
    "    save_path = \"sigmoid_training_history.pdf\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8229023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Plot saved as PDF: /Users/yifanyu/Desktop/mpiNN/tanh_training_history.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_path = \"train_his_csv/loss_record_tanh.csv\"\n",
    "df_relu = pd.read_csv(csv_path)\n",
    "\n",
    "plot_training_history(\n",
    "    df_relu,\n",
    "    x_col=\"epoch\",\n",
    "    y_cols=[\"train_loss\", \"val_loss\"],\n",
    "    title=\"Tanh Activation Training History\",\n",
    "    xlabel=\"Epoch\",\n",
    "    ylabel=\"RMSE\",\n",
    "    legend_fontsize=17,\n",
    "    axis_fontsize=16,\n",
    "    alpha=0.9,\n",
    "    save_path = \"tanh_training_history.pdf\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d29805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c8acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpipy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
